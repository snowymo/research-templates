@article{Sun:2016:MVP,
 author = {Sun, Qi and Wei, Li-Yi and Kaufman, Arie},
 title = {Mapping Virtual and Physical Reality},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2016},
 volume = {35},
 number = {4},
 month = jul,
 year = {2016},
 issn = {0730-0301},
 pages = {64:1--64:12},
 articleno = {64},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2897824.2925883},
 doi = {10.1145/2897824.2925883},
 acmid = {2925883},
 keywords = {camera projection, geometry morphing, head-mounted display, human perception, planar map, real-time rendering, redirected walking, virtual reality, warped space},
} 

@article{mochizuki2012magnitude,
  title={The magnitude of stereopsis in peripheral visual fields},
  author={Mochizuki, Hiroshi and Shoji, Nobuyuki and Ando, Eriko and Otsuka, Maiko and Takahashi, Kenichiro and Handa, Tomoya and others},
  journal={Kitasato Med J},
  volume={41},
  pages={1--5},
  year={2012}
}

@inproceedings{park2019deepsdf,
  title={Deepsdf: Learning continuous signed distance functions for shape representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={165--174},
  year={2019}
}

@article{Serrano_TVCG_VR-6dof,
author = {Ana Serrano and
Incheol Kim and
Zhili Chen and
Stephen DiVerdi and
Diego Gutierrez and			  
Aaron Hertzmann and
Belen Masia},
title     = {Motion parallax for 360$^{\circ}$ RGBD video},
journal   = {IEEE Transactions on Visualization and Computer Graphics},
year      = {2019},
}


@article{Sun:20:OE,
author = {Qi Sun and Fu-Chung Huang and Li-Yi Wei and David Luebke and Arie Kaufman and Joohwan Kim},
journal = {Opt. Express},
keywords = {Binocular vision; Head mounted displays; Light fields; Optical components; Retinal ganglion cells; Visual system},
number = {5},
pages = {6734–6739},
publisher = {OSA},
title = {Eccentricity effects on blur and depth perception},
volume = {28},
month = {Mar},
year = {2020},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-28-5-6734},
doi = {10.1364/OE.28.006734},
}

@article{Tursun:2019:LCA,
author = {Tursun, Okan Tarhan and Arabadzhiyska-Koleva, Elena and Wernikowski, Marek and Mantiuk, Rados\l{}aw and Seidel, Hans-Peter and Myszkowski, Karol and Didyk, Piotr},
title = {Luminance-Contrast-Aware Foveated Rendering},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3306346.3322985},
doi = {10.1145/3306346.3322985},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {98},
numpages = {14},
keywords = {foveated rendering, perception}
}



@inproceedings{Attal:2020:ECCV,
    author    = "Benjamin Attal and Selena Ling and Aaron Gokaslan and
                 Christian Richardt and James Tompkin",
    title     = "{MatryODShka}: Real-time {6DoF} Video View Synthesis
		 using Multi-Sphere Images",
    booktitle = "European Conference on Computer Vision (ECCV)",
    month     = aug,
    year      = "2020",
    url       = "https://visual.cs.brown.edu/matryodshka"
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

@inproceedings{perry2002gaze,
  title={Gaze-contingent real-time simulation of arbitrary visual fields},
  author={Perry, Jeffrey S and Geisler, Wilson S},
  booktitle={Human vision and electronic imaging VII},
  volume={4662},
  pages={57--69},
  year={2002},
  organization={International Society for Optics and Photonics}
}

@InProceedings{Benjamin:2020:RTV,
author="Attal, Benjamin
and Ling, Selena
and Gokaslan, Aaron
and Richardt, Christian
and Tompkin, James",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="MatryODShka: Real-time 6DoF Video View Synthesis Using Multi-sphere Images",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="441--459",
isbn="978-3-030-58452-8"
}



@inproceedings{sitzmann2019siren,
    author = {Sitzmann, Vincent
              and Martel, Julien N.P.
              and Bergman, Alexander W.
              and Lindell, David B.
              and Wetzstein, Gordon},
    title = {Implicit Neural Representations
              with Periodic Activation Functions},
    booktitle = {Proc. NeurIPS},
    year={2020}
}

@inproceedings{sitzmann2019srns,
    author = {Sitzmann, Vincent
              and Zollh{\"o}fer, Michael
              and Wetzstein, Gordon},
    title = {Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations},
    booktitle = {Advances in Neural Information Processing Systems},
    year={2019}
}

@article{Broxton:immersiveLF,
author = {Broxton, Michael and Flynn, John and Overbeck, Ryan and Erickson, Daniel and Hedman, Peter and Duvall, Matthew and Dourgarian, Jason and Busch, Jay and Whalen, Matt and Debevec, Paul},
title = {Immersive Light Field Video with a Layered Mesh Representation},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3386569.3392485},
doi = {10.1145/3386569.3392485},
abstract = {We present a system for capturing, reconstructing, compressing, and rendering high quality immersive light field video. We accomplish this by leveraging the recently introduced DeepView view interpolation algorithm, replacing its underlying multi-plane image (MPI) scene representation with a collection of spherical shells that are better suited for representing panoramic light field content. We further process this data to reduce the large number of shell layers to a small, fixed number of RGBA+depth layers without significant loss in visual quality. The resulting RGB, alpha, and depth channels in these layers are then compressed using conventional texture atlasing and video compression techniques. The final compressed representation is lightweight and can be rendered on mobile VR/AR platforms or in a web browser. We demonstrate light field video results using data from the 16-camera rig of [Pozo et al. 2019] as well as a new low-cost hemispherical array made from 46 synchronized action sports cameras. From this data we produce 6 degree of freedom volumetric videos with a wide 70 cm viewing baseline, 10 pixels per degree angular resolution, and a wide field of view, at 30 frames per second video frame rates. Advancing over previous work, we show that our system is able to reproduce challenging content such as view-dependent reflections, semi-transparent surfaces, and near-field objects as close as 34 cm to the surface of the camera rig.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {86},
numpages = {15},
keywords = {image-based rendering, light fields, deep learning, view synthesis}
}


@InProceedings{Lin:DeepPanorama,
author="Lin, Kai-En
and Xu, Zexiang
and Mildenhall, Ben
and Srinivasan, Pratul P.
and Hold-Geoffroy, Yannick
and DiVerdi, Stephen
and Sun, Qi
and Sunkavalli, Kalyan
and Ramamoorthi, Ravi",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Deep Multi Depth Panoramas for View Synthesis",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="328--344",
isbn="978-3-030-58601-0"
}



@article{LearningViewSynthesis,
    author  = {Nima Khademi Kalantari and Ting-Chun Wang and Ravi Ramamoorthi},
    title   = {Learning-Based View Synthesis for Light Field Cameras},
    journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2016)},
    volume  = {35},
    number  = {6},
    year    = {2016},
}

@inproceedings{gortler1996lumigraph,
  title={The lumigraph},
  author={Gortler, Steven J and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael F},
  booktitle={Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
  pages={43--54},
  year={1996}
}

@inproceedings{winkler2010multi,
  title={Multi-scale geometry interpolation},
  author={Winkler, Tim and Drieseberg, Jens and Alexa, Marc and Hormann, Kai},
  booktitle={Computer graphics forum},
  volume={29},
  number={2},
  pages={309--318},
  year={2010},
  organization={Wiley Online Library}
}

@article{Pozo:2019:I6V,
author = {Pozo, Albert Parra and Toksvig, Michael and Schrager, Terry Filiba and Hsu, Joyce and Mathur, Uday and Sorkine-Hornung, Alexander and Szeliski, Rick and Cabral, Brian},
title = {An Integrated 6DoF Video Camera and System Design},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356555},
doi = {10.1145/3355089.3356555},
abstract = {Designing a fully integrated 360° video camera supporting 6DoF head motion parallax requires overcoming many technical hurdles, including camera placement, optical design, sensor resolution, system calibration, real-time video capture, depth reconstruction, and real-time novel view synthesis. While there is a large body of work describing various system components, such as multi-view depth estimation, our paper is the first to describe a complete, reproducible system that considers the challenges arising when designing, building, and deploying a full end-to-end 6DoF video camera and playback environment. Our system includes a computational imaging software pipeline supporting online markerless calibration, high-quality reconstruction, and real-time streaming and rendering. Most of our exposition is based on a professional 16-camera configuration, which will be commercially available to film producers. However, our software pipeline is generic and can handle a variety of camera geometries and configurations. The entire calibration and reconstruction software pipeline along with example datasets is open sourced to encourage follow-up research in high-quality 6DoF video reconstruction and rendering 1.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {216},
numpages = {16},
keywords = {video stitching, 6DoF}
}

@inproceedings{shum2000review,
  title={Review of image-based rendering techniques},
  author={Shum, Harry and Kang, Sing Bing},
  booktitle={Visual Communications and Image Processing 2000},
  volume={4067},
  pages={2--13},
  year={2000},
  organization={International Society for Optics and Photonics}
}

@inproceedings{levoy1996light,
  title={Light field rendering},
  author={Levoy, Marc and Hanrahan, Pat},
  booktitle={Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
  pages={31--42},
  year={1996}
}

@article{mildenhall2019llff,
  title={Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines},
  author={Ben Mildenhall and Pratul P. Srinivasan and Rodrigo Ortiz-Cayon and Nima Khademi Kalantari and Ravi Ramamoorthi and Ren Ng and Abhishek Kar},
  journal={ACM Transactions on Graphics (TOG)},
  year={2019}
}

@article{Li2020LF, 
    author = {Li, Qinbo and Khademi Kalantari, Nima}, 
    title = {Synthesizing Light Field From a Single Image
    with Variable MPI and Two Network Fusion},
    journal = {ACM Transactions on Graphics}, 
    volume = {39}, 
    number = {6}, 
    year = {2020}, 
    month = {12}, 
    doi = {10.1145/3414685.3417785} 
}

@InProceedings{Li:2020:TSP,
author="Li, Mengtian
and Wang, Yu-Xiong
and Ramanan, Deva",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Towards Streaming Perception",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="473--488",
isbn="978-3-030-58536-5"
}

@article{albert2017latency,
  title={Latency requirements for foveated rendering in virtual reality},
  author={Albert, Rachel and Patney, Anjul and Luebke, David and Kim, Joohwan},
  journal={ACM Transactions on Applied Perception (TAP)},
  volume={14},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}



@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@article{Guenter:2012:F3G,
author = {Guenter, Brian and Finch, Mark and Drucker, Steven and Tan, Desney and Snyder, John},
title = {Foveated 3D Graphics},
year = {2012},
issue_date = {November 2012},
_publisher = {Association for Computing Machinery},
_address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2366145.2366183},
doi = {10.1145/2366145.2366183},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {164},
numpages = {10},
}

@inproceedings{sitzmann2019metasdf,
    author = {Sitzmann, Vincent
              and Chan, Eric R.
              and Tucker, Richard
              and Snavely, Noah
              and Wetzstein, Gordon},
    title = {MetaSDF: Meta-Learning Signed Distance Functions},
    booktitle = {arXiv},
    year={2020}
}
@inproceedings{sitzmann2019deepvoxels,
    author = {Sitzmann, Vincent
              and Thies, Justus
              and Heide, Felix
              and Nie{\ss}ner, Matthias
              and Wetzstein, Gordon
              and Zollh{\"o}fer, Michael},
    title = {DeepVoxels: Learning Persistent 3D Feature Embeddings},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year={2019}
}
    

@article{Kaplanyan:2019:DNR,
author = {Kaplanyan, Anton S. and Sochenov, Anton and Leimk\"{u}hler, Thomas and Okunev, Mikhail and Goodall, Todd and Rufo, Gizem},
title = {DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression Using Learned Statistics of Natural Videos},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356557},
doi = {10.1145/3355089.3356557},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {212},
numpages = {13},
keywords = {gaze-contingent rendering, foveated rendering, perceptual rendering, video generation, video compression, generative networks, deep learning, virtual reality}
}

@misc{StackExchange:2011:HLI,
 title = {How to link images relatively in Inkscape?},
 author = {Stackexchange},
 year = {2011},
 note = {\url{http://graphicdesign.stackexchange.com/questions/4906/how-to-link-images-relatively-in-inkscape}},
}%misc

@article{Sun:2017:PGF,
author = {Sun, Qi and Huang, Fu-Chung and Kim, Joohwan and Wei, Li-Yi and Luebke, David and Kaufman, Arie},
title = {Perceptually-Guided Foveation for Light Field Displays},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3130800.3130807},
doi = {10.1145/3130800.3130807},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {Article 192},
numpages = {13},
keywords = {computational display, light field, foveation, sampling}
}

@article{Patney:2016:TFR,
author = {Patney, Anjul and Salvi, Marco and Kim, Joohwan and Kaplanyan, Anton and Wyman, Chris and Benty, Nir and Luebke, David and Lefohn, Aaron},
title = {Towards Foveated Rendering for Gaze-Tracked Virtual Reality},
year = {2016},
issue_date = {November 2016},
volume = {35},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2980179.2980246},
doi = {10.1145/2980179.2980246},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {Article 179},
numpages = {12},
keywords = {perception, gaze-tracking, foveated rendering, virtual reality}
}

@inproceedings{jiang2015salicon,
  title={Salicon: Saliency in context},
  author={Jiang, Ming and Huang, Shengsheng and Duan, Juanyong and Zhao, Qi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1072--1080},
  year={2015}
}

@inproceedings{mescheder2019occupancy,
  title={Occupancy networks: Learning 3d reconstruction in function space},
  author={Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4460--4470},
  year={2019}
}

@inproceedings{chen2019learning,
  title={Learning implicit fields for generative shape modeling},
  author={Chen, Zhiqin and Zhang, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5939--5948},
  year={2019}
}

@inproceedings{atzmon2020sal,
  title={Sal: Sign agnostic learning of shapes from raw data},
  author={Atzmon, Matan and Lipman, Yaron},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2565--2574},
  year={2020}
}

@article{gropp2020implicit,
  title={Implicit geometric regularization for learning shapes},
  author={Gropp, Amos and Yariv, Lior and Haim, Niv and Atzmon, Matan and Lipman, Yaron},
  journal={arXiv preprint arXiv:2002.10099},
  year={2020}
}

@inproceedings{chabra2020deep,
  title={Deep local shapes: Learning local sdf priors for detailed 3d reconstruction},
  author={Chabra, Rohan and Lenssen, Jan E and Ilg, Eddy and Schmidt, Tanner and Straub, Julian and Lovegrove, Steven and Newcombe, Richard},
  booktitle={European Conference on Computer Vision},
  pages={608--625},
  year={2020},
  organization={Springer}
}

@inproceedings{niemeyer2019occupancy,
  title={Occupancy flow: 4d reconstruction by learning particle dynamics},
  author={Niemeyer, Michael and Mescheder, Lars and Oechsle, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5379--5389},
  year={2019}
}

@inproceedings{saito2019pifu,
  title={Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization},
  author={Saito, Shunsuke and Huang, Zeng and Natsume, Ryota and Morishima, Shigeo and Kanazawa, Angjoo and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2304--2314},
  year={2019}
}

@inproceedings{oechsle2019texture,
  title={Texture fields: Learning texture representations in function space},
  author={Oechsle, Michael and Mescheder, Lars and Niemeyer, Michael and Strauss, Thilo and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4531--4540},
  year={2019}
}

@article{lin2020sdf,
  title={SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images},
  author={Lin, Chen-Hsuan and Wang, Chaoyang and Lucey, Simon},
  journal={arXiv preprint arXiv:2010.10505},
  year={2020}
}

@article{yariv2020multiview,
  title={Multiview neural surface reconstruction by disentangling geometry and appearance},
  author={Yariv, Lior and Kasten, Yoni and Moran, Dror and Galun, Meirav and Atzmon, Matan and Ronen, Basri and Lipman, Yaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{tretschk2020patchnets,
  title={PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape Representations},
  author={Tretschk, Edgar and Tewari, Ayush and Golyanik, Vladislav and Zollh{\"o}fer, Michael and Stoll, Carsten and Theobalt, Christian},
  booktitle={European Conference on Computer Vision},
  pages={293--309},
  year={2020},
  organization={Springer}
}

@article{liu2020neural,
  title={Neural sparse voxel fields},
  author={Liu, Lingjie and Gu, Jiatao and Lin, Kyaw Zaw and Chua, Tat-Seng and Theobalt, Christian},
  journal={arXiv preprint arXiv:2007.11571},
  year={2020}
}