@article{Sun:2016:MVP,
 author = {Sun, Qi and Wei, Li-Yi and Kaufman, Arie},
 title = {Mapping Virtual and Physical Reality},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2016},
 volume = {35},
 number = {4},
 month = jul,
 year = {2016},
 issn = {0730-0301},
 pages = {64:1--64:12},
 articleno = {64},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2897824.2925883},
 doi = {10.1145/2897824.2925883},
 acmid = {2925883},
 keywords = {camera projection, geometry morphing, head-mounted display, human perception, planar map, real-time rendering, redirected walking, virtual reality, warped space},
} 

@inproceedings{sitzmann2019siren,
    author = {Sitzmann, Vincent
              and Martel, Julien N.P.
              and Bergman, Alexander W.
              and Lindell, David B.
              and Wetzstein, Gordon},
    title = {Implicit Neural Representations
              with Periodic Activation Functions},
    booktitle = {Proc. NeurIPS},
    year={2020}
}

@inproceedings{sitzmann2019srns,
    author = {Sitzmann, Vincent
              and Zollh{\"o}fer, Michael
              and Wetzstein, Gordon},
    title = {Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations},
    booktitle = {Advances in Neural Information Processing Systems},
    year={2019}
}

@article{Broxton:immersiveLF,
author = {Broxton, Michael and Flynn, John and Overbeck, Ryan and Erickson, Daniel and Hedman, Peter and Duvall, Matthew and Dourgarian, Jason and Busch, Jay and Whalen, Matt and Debevec, Paul},
title = {Immersive Light Field Video with a Layered Mesh Representation},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3386569.3392485},
doi = {10.1145/3386569.3392485},
abstract = {We present a system for capturing, reconstructing, compressing, and rendering high quality immersive light field video. We accomplish this by leveraging the recently introduced DeepView view interpolation algorithm, replacing its underlying multi-plane image (MPI) scene representation with a collection of spherical shells that are better suited for representing panoramic light field content. We further process this data to reduce the large number of shell layers to a small, fixed number of RGBA+depth layers without significant loss in visual quality. The resulting RGB, alpha, and depth channels in these layers are then compressed using conventional texture atlasing and video compression techniques. The final compressed representation is lightweight and can be rendered on mobile VR/AR platforms or in a web browser. We demonstrate light field video results using data from the 16-camera rig of [Pozo et al. 2019] as well as a new low-cost hemispherical array made from 46 synchronized action sports cameras. From this data we produce 6 degree of freedom volumetric videos with a wide 70 cm viewing baseline, 10 pixels per degree angular resolution, and a wide field of view, at 30 frames per second video frame rates. Advancing over previous work, we show that our system is able to reproduce challenging content such as view-dependent reflections, semi-transparent surfaces, and near-field objects as close as 34 cm to the surface of the camera rig.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {86},
numpages = {15},
keywords = {image-based rendering, light fields, deep learning, view synthesis}
}


@InProceedings{Lin:DeepPanorama,
author="Lin, Kai-En
and Xu, Zexiang
and Mildenhall, Ben
and Srinivasan, Pratul P.
and Hold-Geoffroy, Yannick
and DiVerdi, Stephen
and Sun, Qi
and Sunkavalli, Kalyan
and Ramamoorthi, Ravi",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Deep Multi Depth Panoramas for View Synthesis",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="328--344",
isbn="978-3-030-58601-0"
}



@article{LearningViewSynthesis,
    author  = {Nima Khademi Kalantari and Ting-Chun Wang and Ravi Ramamoorthi},
    title   = {Learning-Based View Synthesis for Light Field Cameras},
    journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2016)},
    volume  = {35},
    number  = {6},
    year    = {2016},
}

@inproceedings{gortler1996lumigraph,
  title={The lumigraph},
  author={Gortler, Steven J and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael F},
  booktitle={Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
  pages={43--54},
  year={1996}
}

@inproceedings{levoy1996light,
  title={Light field rendering},
  author={Levoy, Marc and Hanrahan, Pat},
  booktitle={Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
  pages={31--42},
  year={1996}
}

@InProceedings{Li:2020:TSP,
author="Li, Mengtian
and Wang, Yu-Xiong
and Ramanan, Deva",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Towards Streaming Perception",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="473--488",
isbn="978-3-030-58536-5"
}

@article{albert2017latency,
  title={Latency requirements for foveated rendering in virtual reality},
  author={Albert, Rachel and Patney, Anjul and Luebke, David and Kim, Joohwan},
  journal={ACM Transactions on Applied Perception (TAP)},
  volume={14},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}



@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@article{Guenter:2012:F3G,
author = {Guenter, Brian and Finch, Mark and Drucker, Steven and Tan, Desney and Snyder, John},
title = {Foveated 3D Graphics},
year = {2012},
issue_date = {November 2012},
_publisher = {Association for Computing Machinery},
_address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2366145.2366183},
doi = {10.1145/2366145.2366183},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {164},
numpages = {10},
}

@inproceedings{sitzmann2019metasdf,
    author = {Sitzmann, Vincent
              and Chan, Eric R.
              and Tucker, Richard
              and Snavely, Noah
              and Wetzstein, Gordon},
    title = {MetaSDF: Meta-Learning Signed Distance Functions},
    booktitle = {arXiv},
    year={2020}
}
@inproceedings{sitzmann2019deepvoxels,
    author = {Sitzmann, Vincent
              and Thies, Justus
              and Heide, Felix
              and Nie{\ss}ner, Matthias
              and Wetzstein, Gordon
              and Zollh{\"o}fer, Michael},
    title = {DeepVoxels: Learning Persistent 3D Feature Embeddings},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year={2019}
}
    

@article{Kaplanyan:2019:DNR,
author = {Kaplanyan, Anton S. and Sochenov, Anton and Leimk\"{u}hler, Thomas and Okunev, Mikhail and Goodall, Todd and Rufo, Gizem},
title = {DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression Using Learned Statistics of Natural Videos},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356557},
doi = {10.1145/3355089.3356557},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {212},
numpages = {13},
keywords = {gaze-contingent rendering, foveated rendering, perceptual rendering, video generation, video compression, generative networks, deep learning, virtual reality}
}

@misc{StackExchange:2011:HLI,
 title = {How to link images relatively in Inkscape?},
 author = {Stackexchange},
 year = {2011},
 note = {\url{http://graphicdesign.stackexchange.com/questions/4906/how-to-link-images-relatively-in-inkscape}},
}%misc

@article{Sun:2017:PGF,
author = {Sun, Qi and Huang, Fu-Chung and Kim, Joohwan and Wei, Li-Yi and Luebke, David and Kaufman, Arie},
title = {Perceptually-Guided Foveation for Light Field Displays},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3130800.3130807},
doi = {10.1145/3130800.3130807},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {Article 192},
numpages = {13},
keywords = {computational display, light field, foveation, sampling}
}

@article{Patney:2016:TFR,
author = {Patney, Anjul and Salvi, Marco and Kim, Joohwan and Kaplanyan, Anton and Wyman, Chris and Benty, Nir and Luebke, David and Lefohn, Aaron},
title = {Towards Foveated Rendering for Gaze-Tracked Virtual Reality},
year = {2016},
issue_date = {November 2016},
volume = {35},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2980179.2980246},
doi = {10.1145/2980179.2980246},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {Article 179},
numpages = {12},
keywords = {perception, gaze-tracking, foveated rendering, virtual reality}
}